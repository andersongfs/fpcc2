---
title: "lab5cp2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE}
require(tidyverse)
require(broom)
require(modelr)
```
  
  Queremos avaliar se a beleza possui um efeito significativo no score dos professores, levando em conta os demais fatores que foram identificados como tento possíveis efeitos, que são as variáveis:
  rank, ethnicity, gender, language, age, cls_*, pic_outfit e pic_color.
```{r}
eval = read_csv(file = "../data/evals.csv")
head(eval)
```
## Descritivo dos dados
// TODO

## Regressão  Linear Simples - Questão 2
Para iniciar, vamos criar o modelo linear para o _score_ baseado em *bty_avg* que é a média de beleza do professor.
```{r}
mod_simple <- lm(score ~ bty_avg, data = eval)

tidy(mod_simple, conf.int = TRUE)

```
Pela tabela acima, temos que o **p-value = 0.00005082731** (< 0.05), logo podemos afirmar que a _média de beleza_ tem um efeito significativo no _score_ do professor. Outro indício disso é que o intervalo obtido para a variável _bty_avg_ não inclui o 0, sendo ele [0.03462292, 0.09865116]. Porém, esse efeito significativo **não tem uma significânca prática**, já que o _score_ é pouco alterado pela _média de beleza_(fator de incremento = 0.06).
Como equação do nosso modelo linear temos:
score = valor_intercepto_em_y + fator_de_incremento * bty_avg
score = 3.88 + 0.06 * bty_avg

```{r}
glance(mod_simple)
```
  Dessa tabela podemos observar o r.squared = 0.03, que nos indica um fraco grau de associação dessas duas variáveis por estar próximo de 0, confirmando o que já vimos mais acima onde uma sofre pouca influência da outra. De outra forma, nosso modelo linear baseado na variável *bty_avg* só explica 3% do *score*.
  Abaixo observamos que a reta do modelo tenta se ajustar aos dados mas ainda não temos um resultado tão bom pelo fato dos pontos estarem bastante espalhados.
```{r}
eval %>% 
  add_predictions(model = mod_simple) %>%
  ggplot(mapping = aes(x = bty_avg, y = score)) + 
  geom_point(alpha = 0.4, size = .5) + 
  geom_line(aes(y = pred), colour = "red")
```

Sobre os resíduos temos uma distribuição uniforme deles e não se distanciam muito do 0, porém temos muitos pontos espalhados. Possa ser que realizando transformações nos dados obtivéssemos um resultado melhor.
```{r}
eval %>% 
  add_residuals(model = mod_simple) %>% 
  ggplot(aes(bty_avg, resid)) + 
  geom_point(alpha = .4) + 
  geom_hline(yintercept = 0, colour = "blue")
```

## Regressão Linear Múltipla

Aqui vamos analisar o efeito de múltiplas variáveis no score de forma simultânea. Para isso continuaremos analisando a _média de beleza_ e adicionaremos o _rank_ do professor, supondo que professores com níveis mais altos possuem mais experiência, _age_, supondo que com o passar dos anos os professores vão aprimorando a forma de lecionar e *bty_avg relacionada com a etnia do professor*, pois será que a beleza não seja relativa para o avaliador dependendo da etnia do professor?

```{r}
mod_multi = lm(score ~ bty_avg + rank + age + bty_avg*ethnicity, data = eval)
tidy(mod_multi, conf.int = TRUE)
```
Observando os **p-valores** temos que a única variávei significativa é ranktenure track por aprensentar p-value menor que 0.05. O valor de _ranktenure track_ impacta negativamento em _score_, com fator igual a -0.19 quando modificada.
Além disso, é possível notar que o impacto de bty_avg diminuiu, indo de 0.06 para -0.01 quando adicionamos a relação bty_avg com ethinocity.
```{r}
glance(mod_multi)
```
Com a regressão linear multivariada obtivemos um r.squared = 0.06 nos indicando que este modelo ainda não ocnsegue explicar muita coisa do *score*. Tivemos um aumento de 3% obtido na simples para 6% com a multivariada.

Sobre os resíduos encontramos um padrão o qual nos indica que o modelo não foi adequado, por variar muito na predição, hora subestimando, hora superestimando.
```{r}
adv_eval = eval %>%
    add_predictions(model = mod_multi) %>%
    add_residuals(model = mod_multi)

adv_eval %>% 
  add_residuals(model = mod_multi) %>% 
  ggplot(aes(score, resid)) + 
  geom_point(alpha = .4) + 
  geom_hline(yintercept = 0, colour = "blue")
```

Por fim, notamos que bty_avg tem um impacto insignificante em relação ao score e teríamos que utilizar outras variáveis na tentativa de melhorar o modelo(se é que as variáveis existentes conseguem explicar bem o score).
